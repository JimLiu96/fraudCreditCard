{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install panda\n",
    "# import random\n",
    "# import pandas as pd\n",
    "#from imblearn.under_sampling import ClusterCentroids\n",
    "import dataGenerator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (brier_score_loss, precision_score, recall_score,\n",
    "                             f1_score, roc_curve, confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataGenerator package\n",
    "\n",
    "1. **dataGenererator.splitData()**\n",
    "    return trainFeature, trainLabel, testFeature, testLabel\n",
    "2. **dataGenerator.resampling(trainFeature, trainLabel, alpha = 1, method=\"under_sampling\")**\n",
    "    return resampled balanced features and its corresponding labels. Alpha is the balance factor, it is the ratio between **neg:pos** of the resampled data. method is the sampling method, it can be \"under_sampling\" or \"over_sampling\". \n",
    "    \n",
    "    **\"under_sampling\"** samples the data from negative data which are the majority. \n",
    "    \n",
    "    **\"over_sampling\"** samples from the positive data which are the minority. \n",
    "\n",
    "## Sampling setting\n",
    "\n",
    "Here, we should choose the ratio, i.e. alpha parameter in the resampling function, to be same for different sampling methods. All of us should choose\n",
    "\n",
    "**alpha = [1, 10, 20, 50]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232818\n",
      "(233215, 30) (56961, 30)\n"
     ]
    }
   ],
   "source": [
    "trainFeature, trainLabel, testFeature, testLabel = dataGenerator.splitData()\n",
    "sampleFeature, sampleLabel = dataGenerator.resampling(trainFeature, trainLabel, alpha = 100, method=\"over_sampling\")\n",
    "print(len(sampleLabel[sampleLabel == 0]))\n",
    "# print(sampleLabel)\n",
    "print(trainFeature.shape, testFeature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sample = LogisticRegression(C=1., solver='lbfgs', max_iter = 500)\n",
    "lr_sample.fit(sampleFeature, sampleLabel)\n",
    "sampleLabelPredict = lr_sample.predict(testFeature)\n",
    "prob_pos_sample = lr_sample.predict_proba(testFeature)[:, 1]\n",
    "fpr_sample, tpr_sample, _ = roc_curve(testLabel, prob_pos_sample)\n",
    "\n",
    "# prob_pos = lr_sample.predict_proba(testFeature)[:, 0]\n",
    "# print(testLabelPredict)\n",
    "# trainLabelPredict = lr_sample.predict(trainFeature)\n",
    "# print(\"\\tPrecision: %1.3f\" % precision_score(trainLabelPredict, trainLabel))\n",
    "# print(\"\\tRecall: %1.3f\" % recall_score(trainLabelPredict, trainLabel))\n",
    "# print(\"\\tF1: %1.3f\\n\" % f1_score(trainLabelPredict, trainLabel))\n",
    "sampleConfusion = confusion_matrix(testLabel, sampleLabelPredict)\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(testLabel, sampleLabelPredict))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(testLabel, sampleLabelPredict))\n",
    "print(\"\\tF1: %1.3f\\n\" % f1_score(testLabel, sampleLabelPredict))\n",
    "print(sampleConfusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_full = LogisticRegression(C=1., solver='lbfgs', max_iter = 500)\n",
    "lr_full.fit(trainFeature, trainLabel)\n",
    "testLabelPredict = lr_full.predict(testFeature)\n",
    "prob_pos_test = lr_full.predict_proba(testFeature)[:, 1]\n",
    "fpr_full, tpr_full, _ = roc_curve(testLabel, prob_pos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_full, tpr_full, _ = roc_curve(testLabel, prob_pos_test)\n",
    "testConfusion = confusion_matrix(testLabel, testLabelPredict)\n",
    "print(\"\\tPrecision: %1.3f\" % precision_score(testLabelPredict, testLabel))\n",
    "print(\"\\tRecall: %1.3f\" % recall_score(testLabelPredict, testLabel))\n",
    "print(\"\\tF1: %1.3f\\n\" % f1_score(testLabelPredict, testLabel))\n",
    "print(testConfusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_sample, tpr_sample, label='sampled lr')\n",
    "plt.plot(fpr_full, tpr_full, label='fully lr')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zhiweitensorflow3]",
   "language": "python",
   "name": "conda-env-zhiweitensorflow3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
